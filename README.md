# Q-Learning Game Client - Explica√ß√£o e Setup

Este documento explica o funcionamento b√°sico do `client.py`, que utiliza Q-Learning para treinar um agente em um ambiente de jogo controlado por socket.

## üß† Estrutura do `client.py`

### 1. Classe `QLearningAgent`
Cont√©m a l√≥gica do agente inteligente. Os principais componentes s√£o:

- `alpha`: taxa de aprendizado (0 < alpha ‚â§ 1)
- `gamma`: fator de desconto futuro (0 < gamma ‚â§ 1)
- `epsilon`: taxa de explora√ß√£o (probabilidade de agir aleatoriamente)

#### M√©todos importantes:
- `choose_action(state_idx)`: aplica a pol√≠tica Œµ-greedy para escolher uma a√ß√£o.
- `update_q_table(...)`: atualiza a Q-table com base na equa√ß√£o Q-learning.
- `state_to_index(state_bin)`: converte um estado bin√°rio (ex: `0b1000111`) em um √≠ndice entre 0 e 95.
- `train(socket_conn, episodes, max_steps)`: faz o loop de aprendizado principal.
- `save_q_table(filename)`: salva a Q-table ap√≥s o treinamento.

### 2. Fun√ß√£o `main()`
Executa o processo completo:
1. L√™ os argumentos via `argparse`:
   - `--episodes`: n√∫mero de epis√≥dios de treino.
   - `--port`: porta para conectar ao servidor do jogo.
2. Cria o socket.
3. Executa o treinamento.
4. Salva a Q-table.
5. Fecha a conex√£o.

## ‚öôÔ∏è Setup Inicial

### Pr√©-requisitos
- Python 3.7+
- Socket server rodando localmente na porta especificada (ex: 2037)

### Instala√ß√£o
Crie um ambiente virtual e instale depend√™ncias:
```bash
python -m venv env
source env/bin/activate  # Windows: env\\Scripts\\activate
pip install -r requirements.txt  # se existir
